Tokenizer encoder here basically divides the whole line into small tokens . Byte pair encoder is used that tokenizes the word into small subwords . If a word is not found in its vocablary then it basically divides into small subwords in the manner it finds best .
<img width="853" height="151" alt="image" src="https://github.com/user-attachments/assets/4b3d61cc-12db-448d-8819-6b30e0da1c40" />
Here decoder is also in work that converts tokens back into the whole sentence .
<img width="1141" height="110" alt="image" src="https://github.com/user-attachments/assets/30f8d16e-b97d-4701-9159-f5d186787744" />
<img width="1123" height="102" alt="image" src="https://github.com/user-attachments/assets/1429a7ba-9897-4e3e-bf49-5345573b95ba" />



