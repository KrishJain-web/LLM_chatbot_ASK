Tokenizer encoder here basically divides the whole line into small tokens . Byte pair encoder is used that tokenizes the word into small subwords . If a word is not found in its vocablary then it basically divides into small subwords in the manner it finds best .
<img width="1127" height="97" alt="image" src="https://github.com/user-attachments/assets/e48e516c-4c49-4732-9c2a-43f1043aaf08" />

Here decoder is also in work that converts tokens back into the whole sentence .
<img width="1141" height="110" alt="image" src="https://github.com/user-attachments/assets/30f8d16e-b97d-4701-9159-f5d186787744" />


